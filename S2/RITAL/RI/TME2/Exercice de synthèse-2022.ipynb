{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exercice de synthèse\n",
        "\n",
        "On s'intéresse ici à résoudre la tâche de [TREC CAST](http://www.treccast.ai/) qui modélise une session de recherche conversationnelle : \n",
        "\n",
        "- l'utilisateur pose des questions à un système de dialogue\n",
        "- le système de dialogue lui répond\n",
        "- on peut imagine que le système de dialogue est associé à un moteur de recherche et pour chaque question soumet une requête au système de RI pour trouver des documents.\n",
        "\n",
        "La tâche traitée ici est d'ordonnancer des documents à un instant *t* compte tenu de l'historique des requêtes. Plusieurs stratégies peuvent être mises en place (pouvant être cumulées ou pas selon vos envies) : \n",
        "\n",
        "- Construire un vecteur de contexte\n",
        "- Reformuler les requêtes en fonction du contexte (historique ou vecteur)\n",
        "- Sélectionner dans l'historique les éléments importants\n",
        "- Ordonnancement global avec prise en compte du contexte\n",
        "- ...\n",
        "\n",
        "L'objectif ici est de mettre en place plusieurs modèles de votre choix, les comparer. Vous avez le droit : \n",
        "- d'utiliser des techniques vues dans les cours précédents de l'école d'été\n",
        "- d'utiliser des datasets externes. \n",
        "\n",
        "\n",
        "Vous pouvez vous mettre en groupe pour discuter. C'est autant un travail d'implémentation que de recherche pour trouver quelle modélisation serait pertinente (et comme tout travail de recherche, je n'ai pas la réponse absolue ! ;) )\n",
        "\n",
        "A vous de jouer !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Jeux de données\n",
        "\n",
        "Le challenge est composé des données suivantes : \n",
        "- jeu de données MSMarco dont l'index est stocké [ici](https://drive.google.com/drive/folders/1q1djRDCGkGBojcEBjToEF2s_VH9jAAXB?usp=sharing)\n",
        "- les requêtes et les jugements de pertinence sont disponibles [ici](https://github.com/daltonj/treccastweb/blob/master/2019/) \n",
        "\n",
        "Le format des fichiers (requêtes et jugements de pertinence) est celui de TREC : \n",
        "- Pour les requêtes : on retrouve l'identifiant des requêtes et le texte associé. A noter, les requêtes sont sous le format x_y : x pour l'identifiant de la session et y pour l'itération de la session. Cela permet de modéliser la séquence de requêtes au sein d'une session (et donc l'historique).\n",
        "```\n",
        "<query>\n",
        "<number>1_1</number>\n",
        "<text>#combine(physician assistant )</text>\n",
        "</query>\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "- Pour les jugements de pertinence : id requête, 0, id document précédé de la collection (e.g. : MARCO_ à enlever), niveau de pertinence.\n",
        "\n",
        "\n",
        "```\n",
        "1_1 0 MARCO_955948 2\n",
        "1_1 0 MARCO_6203672 2\n",
        "1_1 0 MARCO_849267 0\n",
        "1_1 0 MARCO_2331424 0\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "**Note importante** : les jugements de pertinence ont des préfixes différents faisant référence à différents jeux de données (MSMARCO, CAR, ...). C'est lié au fait que la tâche TREC CAST repose sur plusieurs index de documents. Pour faire simple, on ne considère ici que MSMARCO, donc ne prendre en compte que les jugements de pertinence qui lui sont associés."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pour charger des données depuis google drive :"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pyterrier as pt\n",
        "\n",
        "if not pt.started():\n",
        "    pt.init(tqdm='notebook')\n",
        "\n",
        "#récupération de l'index déja créé\n",
        "# if index exists\n",
        "pt.get_dataset(\"msmarco_passage\")\n",
        "indexref = pt.IndexRef.of(\"./etal2021/passage_index/data.properties\")\n",
        "# print(indexref.toString())\n",
        "index = pt.IndexFactory.of(indexref)\n",
        "print(index.getCollectionStatistics().toString())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 0
}
