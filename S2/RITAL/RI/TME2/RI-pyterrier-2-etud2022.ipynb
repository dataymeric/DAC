{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Learning-to-rank : pyTerrier - OpenNIR\n",
        "\n",
        "Dans cette partie, on s'intéresse à l'utilisation de modèles neuronaux pour la recherche d'information. \n",
        "Les modèles neuronaux utilisés ont été rassemblés dans la librairie [OpenNIR](https://opennir.net/). \n",
        "On explorera également le modèle T5 avec le plugin [monoT5](https://github.com/terrierteam/pyterrier_t5)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install --upgrade python-terrier\n",
        "!pip install --upgrade git+https://github.com/Georgetown-IR-Lab/OpenNIR\n",
        "!pip install --upgrade git+https://github.com/terrierteam/pyterrier_t5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialisation\n",
        "De façon similaire au TP1, on initialise PyTerrier. Nous allons travailler sur le dataset CORD19. le bloc suivant est une répétition du code en TP1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n"
          ]
        }
      ],
      "source": [
        "print(os.path.exists(\"terrier_index.zip\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-06-17 12:53:26--  http://www.dcs.gla.ac.uk/~craigm/ecir2021-tutorial/terrier_index.zip\n",
            "Resolving www.dcs.gla.ac.uk (www.dcs.gla.ac.uk)... 130.209.240.1\n",
            "Connecting to www.dcs.gla.ac.uk (www.dcs.gla.ac.uk)|130.209.240.1|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42017186 (40M) [application/zip]\n",
            "Saving to: ‘terrier_index.zip’\n",
            "\n",
            "terrier_index.zip   100%[===================>]  40.07M  7.66MB/s    in 6.0s    \n",
            "\n",
            "2021-06-17 12:53:34 (6.69 MB/s) - ‘terrier_index.zip’ saved [42017186/42017186]\n",
            "\n",
            "Archive:  terrier_index.zip\n",
            "  inflating: terrier_index/data.lexicon.fsomapfile  \n",
            "  inflating: terrier_index/data.properties  \n",
            "  inflating: terrier_index/data.lexicon.fsomaphash  \n",
            "  inflating: terrier_index/data.lexicon.fsomapid  \n",
            "  inflating: terrier_index/data.meta.idx  \n",
            "  inflating: terrier_index/data.direct.bf  \n",
            "  inflating: terrier_index/data.inverted.bf  \n",
            "  inflating: terrier_index/data.meta.zdata  \n",
            "  inflating: terrier_index/data.document.fsarrayfile  \n"
          ]
        }
      ],
      "source": [
        "#Si le chargement de la collection est trop long à cause du débit ou autres raisons,\n",
        "# il est possible de récupérer directement l'index fourni par Terrier\n",
        "import os\n",
        "\n",
        "if not os.path.exists(\"terrier_index.zip\"):\n",
        "  !wget http://www.dcs.gla.ac.uk/~craigm/ecir2021-tutorial/terrier_index.zip\n",
        "  !unzip -j terrier_index.zip -d terrier_index\n",
        "\n",
        "index_ref = pt.IndexRef.of(\"./terrier_index/data.properties\")\n",
        "index = pt.IndexFactory.of(index_ref)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modèles de ré-ordonancement neuronaux \"from scratch\"\n",
        "\n",
        "Les modèles de ré-ordonnancement dans OpenNIR sont constitués de deux éléments :\n",
        "*  ranker: un modèle d'ordonnancement (e.g., drmm, knrm, pacrr, ...). Cf la liste des [Rankers](https://opennir.net/rankers.html).\n",
        "*  vocab : défnit comment le texte est encodé par le modèle (e.g., wordvec_hash, bert, ...). Cela permet ainsi de tester plusieurs méthodes de représentation. Plus de détails concernant le [vocab](https://opennir.net/vocab.html).\n",
        "\n",
        "Les modèles de réordonnancement s'appuient sur une première étape d'ordonnancement (souvent BM25), récupèrent ensuite les textes des top documents et appliquent ensuite le modèle neuronal.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Une fois le modèle chargé, il est nécessaire de mettre en place la pipeline d'évaluation vue dans le tp1. \n",
        "Le modèle neuronal n'est pas efficace car il n'a pas été entraîné et utilise des poids aléatoires."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Entraînement des modèles sur les jeux de données\n",
        "\n",
        "Pour entraîner les modèles, il est nécessaire de construire la pipeline de modèles/transformations à utliser et ensuite d'appliquer la fonction .fit() à la pipeline. \n",
        "Le code ci-dessous prend beaucoup de temps. Il est donné à titre indicatif si vous souhaitez l'utiliser sur des serveurs adaptés. L'étape suivante permet de charger directement les poids du modèle pré-entraîné à l'avance et mis à disposition de la communauté.\n",
        "\n",
        "Dans ce qui suit, on utilise le jeu de données MS MARCO medical pour pré-entraîner le modèle qui sera ensuite appliqué sur CORD19. \n",
        "Il est également possible de garder seulement le jeu de données CORD19, de le découper en train/val/test et regarder les performances. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apprentissage du modèle sur des données médicales (MS MARCO medical)\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_ds = pt.datasets.get_dataset('irds:msmarco-passage/train/medical')\n",
        "train_topics, valid_topics = train_test_split(train_ds.get_topics(), test_size=50, random_state=42)\n",
        "\n",
        "# Indexation de MS MARCO pour la première étape d'ordonnancement et récupérer les textes (pour le ranker openNIR)\n",
        "indexer = pt.index.IterDictIndexer('./terrier_msmarco-passage')\n",
        "tr_index_ref = indexer.index(train_ds.get_corpus_iter(), fields=('text',), meta=('docno',))\n",
        "\n",
        "pipeline = (pt.BatchRetrieve(tr_index_ref) % 100 # récupère les 100 premiers documents\n",
        "            >> pt.text.get_text(train_ds, 'text') # récupère le texte de ces documents\n",
        "            >> pt.apply.generic(lambda df: df.rename(columns={'text': 'abstract'})) # renomme la colonne\n",
        "            >> knrm) # applique le re-ranker\n",
        "\n",
        "\n",
        "pipeline.fit(\n",
        "    train_topics,\n",
        "    train_ds.get_qrels(),\n",
        "    valid_topics,\n",
        "    train_ds.get_qrels())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pour éviter l'étape d'entraînement ici, on utlise une version pré-entraînée.\n",
        "\n",
        "**Important** : penser à supprimer la mémoire des re-rankers qui vont être mis à jour avec les modèles pré-entrainés."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Il est ensuire possible de lancer la pipeline d'évaluation avec ce nouveau modèle. Les résultats sont meilleurs !"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[02;37m[2021-06-17 13:04:42,066][onir_pt][DEBUG] \u001b[0m\u001b[37musing GPU (deterministic)\u001b[0m\n",
            "\u001b[02;37m[2021-06-17 13:04:42,314][onir_pt][DEBUG] \u001b[0m\u001b[37m[starting] batches\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5948769b98ba47509fdc2794d138eff7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='batches', max=1250.0, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r\u001b[02;37m[2021-06-17 13:04:45,889][onir_pt][DEBUG] \u001b[0m\u001b[37m[finished] batches: [3.57s] [1250it] [350.03it/s]\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>map</th>\n",
              "      <th>P.10</th>\n",
              "      <th>ndcg</th>\n",
              "      <th>ndcg_cut.10</th>\n",
              "      <th>mrt</th>\n",
              "      <th>map +</th>\n",
              "      <th>map -</th>\n",
              "      <th>map p-value</th>\n",
              "      <th>P.10 +</th>\n",
              "      <th>P.10 -</th>\n",
              "      <th>P.10 p-value</th>\n",
              "      <th>ndcg +</th>\n",
              "      <th>ndcg -</th>\n",
              "      <th>ndcg p-value</th>\n",
              "      <th>ndcg_cut.10 +</th>\n",
              "      <th>ndcg_cut.10 -</th>\n",
              "      <th>ndcg_cut.10 p-value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DPH</td>\n",
              "      <td>0.068006</td>\n",
              "      <td>0.658</td>\n",
              "      <td>0.165607</td>\n",
              "      <td>0.609058</td>\n",
              "      <td>77.418922</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DPH &gt;&gt; KNRM</td>\n",
              "      <td>0.065055</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.160497</td>\n",
              "      <td>0.533312</td>\n",
              "      <td>164.292696</td>\n",
              "      <td>20.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.096372</td>\n",
              "      <td>12.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.028682</td>\n",
              "      <td>20.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.027746</td>\n",
              "      <td>20.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>0.006401</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          name       map  ...  ndcg_cut.10 -  ndcg_cut.10 p-value\n",
              "0          DPH  0.068006  ...            NaN                  NaN\n",
              "1  DPH >> KNRM  0.065055  ...           30.0             0.006401\n",
              "\n",
              "[2 rows x 18 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipeline = br >> pt.text.get_text(dataset, 'abstract') >> knrm\n",
        "pt.Experiment(\n",
        "    [br, pipeline],\n",
        "    topics,\n",
        "    qrels,\n",
        "    names=['DPH', 'DPH >> KNRM'],\n",
        "    baseline=0,       ## spécifie quelle est le modèle de référence pour calculer les améliorations.\n",
        "    eval_metrics=[\"map\", \"ndcg\", 'ndcg_cut.10', 'P.10', 'mrt']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Exercice 1**\n",
        "\n",
        "On souhaite savoir quel est le nombre de documents pertinents qu'il est nécessaire de retourner à l'étape de pré-ordonnancement pour utiliser ensuite le modèle KNRM. Ecrire la pipeline de traitement permettant de trouver la valeur optimale de ce paramètre (valeurs de 10 à 100 par pas de 10).\n",
        "\n",
        "Remarque : Ne pas faire de train/test exceptionnellement, on souhaite juste constater la valeur qui maximise sur le jeu de données.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[02;37m[2021-06-17 13:10:49,566][onir_pt][DEBUG] \u001b[0m\u001b[37musing GPU (deterministic)\u001b[0m\n",
            "\u001b[02;37m[2021-06-17 13:10:49,568][onir_pt][DEBUG] \u001b[0m\u001b[37m[starting] batches\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f958a2980d60494e80c53be94b408b05",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='batches', max=125.0, style=ProgressStyle(description_widt…"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r\u001b[02;37m[2021-06-17 13:10:49,994][onir_pt][DEBUG] \u001b[0m\u001b[37m[finished] batches: [425ms] [125it] [294.18it/s]\u001b[0m\n",
            "\u001b[02;37m[2021-06-17 13:10:53,013][onir_pt][DEBUG] \u001b[0m\u001b[37musing GPU (deterministic)\u001b[0m\n",
            "\u001b[02;37m[2021-06-17 13:10:53,015][onir_pt][DEBUG] \u001b[0m\u001b[37m[starting] batches\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e42e9495d6b4a529766d2dedf185cb3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='batches', max=250.0, style=ProgressStyle(description_widt…"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r\u001b[02;37m[2021-06-17 13:10:53,761][onir_pt][DEBUG] \u001b[0m\u001b[37m[finished] batches: [745ms] [250it] [335.38it/s]\u001b[0m\n",
            "\u001b[02;37m[2021-06-17 13:10:56,806][onir_pt][DEBUG] \u001b[0m\u001b[37musing GPU (deterministic)\u001b[0m\n",
            "\u001b[02;37m[2021-06-17 13:10:56,808][onir_pt][DEBUG] \u001b[0m\u001b[37m[starting] batches\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1eeed02bf3d5456cb53269d56aa66ad7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='batches', max=375.0, style=ProgressStyle(description_widt…"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r\u001b[02;37m[2021-06-17 13:10:57,914][onir_pt][DEBUG] \u001b[0m\u001b[37m[finished] batches: [1.11s] [375it] [339.20it/s]\u001b[0m\n",
            "\u001b[02;37m[2021-06-17 13:11:00,767][onir_pt][DEBUG] \u001b[0m\u001b[37musing GPU (deterministic)\u001b[0m\n",
            "\u001b[02;37m[2021-06-17 13:11:00,769][onir_pt][DEBUG] \u001b[0m\u001b[37m[starting] batches\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52b34da3461d46308b6eede52978b79a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='batches', max=500.0, style=ProgressStyle(description_widt…"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r\u001b[02;37m[2021-06-17 13:11:02,220][onir_pt][DEBUG] \u001b[0m\u001b[37m[finished] batches: [1.45s] [500it] [344.77it/s]\u001b[0m\n",
            "\u001b[02;37m[2021-06-17 13:11:05,265][onir_pt][DEBUG] \u001b[0m\u001b[37musing GPU (deterministic)\u001b[0m\n",
            "\u001b[02;37m[2021-06-17 13:11:05,266][onir_pt][DEBUG] \u001b[0m\u001b[37m[starting] batches\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82dc5058a6a144f6b3f10ae95199c879",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='batches', max=625.0, style=ProgressStyle(description_widt…"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r\u001b[02;37m[2021-06-17 13:11:07,059][onir_pt][DEBUG] \u001b[0m\u001b[37m[finished] batches: [1.79s] [625it] [348.83it/s]\u001b[0m\n",
            "\u001b[02;37m[2021-06-17 13:11:10,166][onir_pt][DEBUG] \u001b[0m\u001b[37musing GPU (deterministic)\u001b[0m\n",
            "\u001b[02;37m[2021-06-17 13:11:10,168][onir_pt][DEBUG] \u001b[0m\u001b[37m[starting] batches\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae471dff9d8f45688d41d48c5431699b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='batches', max=750.0, style=ProgressStyle(description_widt…"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r\u001b[02;37m[2021-06-17 13:11:12,304][onir_pt][DEBUG] \u001b[0m\u001b[37m[finished] batches: [2.13s] [750it] [351.32it/s]\u001b[0m\n",
            "\u001b[02;37m[2021-06-17 13:11:15,280][onir_pt][DEBUG] \u001b[0m\u001b[37musing GPU (deterministic)\u001b[0m\n",
            "\u001b[02;37m[2021-06-17 13:11:15,282][onir_pt][DEBUG] \u001b[0m\u001b[37m[starting] batches\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8fc861b94efe46f1b732b05f5c9f89bd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='batches', max=875.0, style=ProgressStyle(description_widt…"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r\u001b[02;37m[2021-06-17 13:11:17,794][onir_pt][DEBUG] \u001b[0m\u001b[37m[finished] batches: [2.51s] [875it] [348.46it/s]\u001b[0m\n",
            "\u001b[02;37m[2021-06-17 13:11:20,786][onir_pt][DEBUG] \u001b[0m\u001b[37musing GPU (deterministic)\u001b[0m\n",
            "\u001b[02;37m[2021-06-17 13:11:20,788][onir_pt][DEBUG] \u001b[0m\u001b[37m[starting] batches\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "792da51c183d4343a37c4f088373c65d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='batches', max=1000.0, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r\u001b[02;37m[2021-06-17 13:11:23,650][onir_pt][DEBUG] \u001b[0m\u001b[37m[finished] batches: [2.86s] [1000it] [349.48it/s]\u001b[0m\n",
            "\u001b[02;37m[2021-06-17 13:11:26,612][onir_pt][DEBUG] \u001b[0m\u001b[37musing GPU (deterministic)\u001b[0m\n",
            "\u001b[02;37m[2021-06-17 13:11:26,614][onir_pt][DEBUG] \u001b[0m\u001b[37m[starting] batches\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1194f0cb0ad4783894f5108c2e45148",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='batches', max=1125.0, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r\u001b[02;37m[2021-06-17 13:11:29,792][onir_pt][DEBUG] \u001b[0m\u001b[37m[finished] batches: [3.18s] [1125it] [354.01it/s]\u001b[0m\n",
            "\u001b[02;37m[2021-06-17 13:11:32,797][onir_pt][DEBUG] \u001b[0m\u001b[37musing GPU (deterministic)\u001b[0m\n",
            "\u001b[02;37m[2021-06-17 13:11:32,799][onir_pt][DEBUG] \u001b[0m\u001b[37m[starting] batches\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d2d2165728c4326ac31583fa456d853",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='batches', max=1250.0, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r\u001b[02;37m[2021-06-17 13:11:36,324][onir_pt][DEBUG] \u001b[0m\u001b[37m[finished] batches: [3.52s] [1250it] [354.65it/s]\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>map</th>\n",
              "      <th>recip_rank</th>\n",
              "      <th>ndcg</th>\n",
              "      <th>ndcg_cut.10</th>\n",
              "      <th>mrt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>c=10</td>\n",
              "      <td>0.011818</td>\n",
              "      <td>0.785333</td>\n",
              "      <td>0.049207</td>\n",
              "      <td>0.596295</td>\n",
              "      <td>64.393072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>c=20</td>\n",
              "      <td>0.020960</td>\n",
              "      <td>0.797500</td>\n",
              "      <td>0.071991</td>\n",
              "      <td>0.585919</td>\n",
              "      <td>72.503793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c=30</td>\n",
              "      <td>0.029337</td>\n",
              "      <td>0.805667</td>\n",
              "      <td>0.089965</td>\n",
              "      <td>0.598224</td>\n",
              "      <td>80.423479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>c=40</td>\n",
              "      <td>0.034766</td>\n",
              "      <td>0.803524</td>\n",
              "      <td>0.102680</td>\n",
              "      <td>0.578190</td>\n",
              "      <td>83.436773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>c=50</td>\n",
              "      <td>0.040644</td>\n",
              "      <td>0.820667</td>\n",
              "      <td>0.114596</td>\n",
              "      <td>0.590963</td>\n",
              "      <td>94.103628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>c=60</td>\n",
              "      <td>0.046914</td>\n",
              "      <td>0.810667</td>\n",
              "      <td>0.125965</td>\n",
              "      <td>0.587072</td>\n",
              "      <td>102.124375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>c=70</td>\n",
              "      <td>0.051899</td>\n",
              "      <td>0.816333</td>\n",
              "      <td>0.136310</td>\n",
              "      <td>0.578087</td>\n",
              "      <td>106.917538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>c=80</td>\n",
              "      <td>0.056869</td>\n",
              "      <td>0.804667</td>\n",
              "      <td>0.144962</td>\n",
              "      <td>0.565164</td>\n",
              "      <td>114.414075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>c=90</td>\n",
              "      <td>0.061794</td>\n",
              "      <td>0.806333</td>\n",
              "      <td>0.154542</td>\n",
              "      <td>0.570981</td>\n",
              "      <td>120.085217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>c=100</td>\n",
              "      <td>0.065055</td>\n",
              "      <td>0.767889</td>\n",
              "      <td>0.160497</td>\n",
              "      <td>0.533312</td>\n",
              "      <td>127.837828</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    name       map  recip_rank      ndcg  ndcg_cut.10         mrt\n",
              "0   c=10  0.011818    0.785333  0.049207     0.596295   64.393072\n",
              "1   c=20  0.020960    0.797500  0.071991     0.585919   72.503793\n",
              "2   c=30  0.029337    0.805667  0.089965     0.598224   80.423479\n",
              "3   c=40  0.034766    0.803524  0.102680     0.578190   83.436773\n",
              "4   c=50  0.040644    0.820667  0.114596     0.590963   94.103628\n",
              "5   c=60  0.046914    0.810667  0.125965     0.587072  102.124375\n",
              "6   c=70  0.051899    0.816333  0.136310     0.578087  106.917538\n",
              "7   c=80  0.056869    0.804667  0.144962     0.565164  114.414075\n",
              "8   c=90  0.061794    0.806333  0.154542     0.570981  120.085217\n",
              "9  c=100  0.065055    0.767889  0.160497     0.533312  127.837828"
            ]
          },
          "execution_count": 10,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cutoffs = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "dph = pt.BatchRetrieve(index)\n",
        "res = pt.Experiment(\n",
        "    [dph % cutoff >> pt.text.get_text(dataset, 'abstract') >> knrm for cutoff in cutoffs],\n",
        "    dataset.get_topics('description'),\n",
        "    dataset.get_qrels(),\n",
        "    names=[f'c={cutoff}' for cutoff in cutoffs],\n",
        "    eval_metrics=[\"map\", \"recip_rank\", \"ndcg\", \"ndcg_cut.10\", \"mrt\"]\n",
        ")\n",
        "res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modèle Vanilla BERT\n",
        "\n",
        "**Exercice 2**\n",
        "\n",
        "Sur le même principe que le modèle KNRM, analyser les performances du modèle vanilla BERT sans et avec pré-entraînement.\n",
        "Pour la version du modèle pré-entraîné, on utilisera le checkpoint ['https://macavaney.us/scibert-medmarco.tar.gz']('https://macavaney.us/scibert-medmarco.tar.gz') avec le paramètre expected_md5=\"854966d0b61543ffffa44cea627ab63b\".\n",
        "\n",
        "Synthétisez toutes les mesures d'évaluation dans un même tableau (bm25, knrm et Vanilla Bert / avec/sans entraînement)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## VBert sans pré-traitement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Chargement du checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Comparaison des performances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MonoT5\n",
        "\n",
        "Pour expérimenter le modèle T5, on utilisera une librairie différente implémentée par pyTerrier. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyterrier_t5 import MonoT5ReRanker\n",
        "monoT5 = MonoT5ReRanker(text_field='abstract')\n",
        "\n",
        "br = pt.BatchRetrieve(index) % 30\n",
        "pipeline = (br >> pt.text.get_text(dataset, 'abstract') >> monoT5)\n",
        "pt.Experiment(\n",
        "    [br, pipeline],\n",
        "    dataset.get_topics('description'),\n",
        "    dataset.get_qrels(),\n",
        "    names=['DPH', 'DPH >> T5'],\n",
        "    eval_metrics=[\"map\", \"recip_rank\", \"ndcg\", \"ndcg_cut.10\", \"mrt\"]\n",
        ")"
      ]
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 0
}
